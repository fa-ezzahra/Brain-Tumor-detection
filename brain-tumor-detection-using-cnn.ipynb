{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réseau de Neurones Convolutif pour la Détection et le Diagnostic des Tumeurs Cérébrales \n",
    "(PyTorch, F1-score : 0,97)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:04.712644Z",
     "iopub.status.busy": "2024-12-28T17:05:04.711803Z",
     "iopub.status.idle": "2024-12-28T17:05:20.697358Z",
     "shell.execute_reply": "2024-12-28T17:05:20.69625Z",
     "shell.execute_reply.started": "2024-12-28T17:05:04.712613Z"
    },
    "papermill": {
     "duration": 11.048635,
     "end_time": "2022-12-25T14:49:51.627145",
     "exception": false,
     "start_time": "2022-12-25T14:49:40.57851",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install split-folders\n",
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.7004Z",
     "iopub.status.busy": "2024-12-28T17:05:20.699678Z",
     "iopub.status.idle": "2024-12-28T17:05:20.707802Z",
     "shell.execute_reply": "2024-12-28T17:05:20.707084Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.700364Z"
    },
    "papermill": {
     "duration": 2.009705,
     "end_time": "2022-12-25T14:49:40.56405",
     "exception": false,
     "start_time": "2022-12-25T14:49:38.554345",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Importation des bibliothèques essentielles\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='darkgrid')\n",
    "import copy # Un module qui fournit des fonctions pour créer des copies d'objets, utile pour éviter les modifications involontaires des variables.\n",
    "import os \n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms # Un module de la bibliothèque torchvision qui fournit des transformations d'images courantes, telles que le redimensionnement, le recadrage et la normalisation.\n",
    "from torch.utils.data import random_split \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau ## Un planificateur PyTorch qui ajuste le taux d'apprentissage pendant l'entraînement en fonction d'une métrique spécifiée, en le réduisant lorsque cette métrique atteint un plateau.\n",
    "import torch.nn as nn # Un module de PyTorch qui fournit des classes pour définir et construire des réseaux de neurones.\n",
    "from torchvision import utils \n",
    "from torchvision.datasets import ImageFolder\n",
    "import splitfolders\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import pathlib\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools \n",
    "from tqdm.notebook import trange, tqdm \n",
    "from torch import optim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.709552Z",
     "iopub.status.busy": "2024-12-28T17:05:20.708973Z",
     "iopub.status.idle": "2024-12-28T17:05:20.7195Z",
     "shell.execute_reply": "2024-12-28T17:05:20.718822Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.709519Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.030458,
     "end_time": "2022-12-25T14:49:51.670755",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.640297",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML, Javascript\n",
    "\n",
    "color_map = ['#FFFFFF','#FF5733']\n",
    "\n",
    "prompt = color_map[-1]\n",
    "main_color = color_map[0]\n",
    "strong_main_color = color_map[1]\n",
    "custom_colors = [strong_main_color, main_color]\n",
    "\n",
    "css_file = '''\n",
    "div #notebook {\n",
    "background-color: white;\n",
    "line-height: 20px;\n",
    "}\n",
    "\n",
    "#notebook-container {\n",
    "%s\n",
    "margin-top: 2em;\n",
    "padding-top: 2em;\n",
    "border-top: 4px solid %s;\n",
    "-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n",
    "    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5);\n",
    "}\n",
    "\n",
    "div .input {\n",
    "margin-bottom: 1em;\n",
    "}\n",
    "\n",
    ".rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\n",
    "color: %s;\n",
    "font-weight: 600;\n",
    "}\n",
    "\n",
    "div.input_area {\n",
    "border: none;\n",
    "    background-color: %s;\n",
    "    border-top: 2px solid %s;\n",
    "}\n",
    "\n",
    "div.input_prompt {\n",
    "color: %s;\n",
    "}\n",
    "\n",
    "div.output_prompt {\n",
    "color: %s; \n",
    "}\n",
    "\n",
    "div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\n",
    "background: %s;\n",
    "}\n",
    "\n",
    "div.cell.selected, div.cell.selected.jupyter-soft-selected {\n",
    "    border-color: %s;\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected:before {\n",
    "background: %s;\n",
    "}\n",
    "\n",
    ".edit_mode div.cell.selected {\n",
    "border-color: %s;\n",
    "\n",
    "}\n",
    "'''\n",
    "\n",
    "def to_rgb(h): \n",
    "    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n",
    "\n",
    "main_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\n",
    "open('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba, \n",
    "                                            main_color,  main_color, prompt, main_color, main_color, \n",
    "                                            main_color, main_color))\n",
    "\n",
    "def nb(): \n",
    "    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\n",
    "nb()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012391,
     "end_time": "2022-12-25T14:49:51.721212",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.708821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>1 <span style='color:#e61227'>|</span> Introduction</b> \n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>1.1 |</span></b> Pourquoi avons-nous besoin de cette étude ?</b></p>\n",
    "</div>\n",
    "\n",
    "**L'apprentissage profond** est devenu un outil puissant dans le domaine de **l'imagerie médicale** et a montré un grand potentiel pour aider la communauté médicale dans la détection et le diagnostic des **tumeurs cérébrales**. En utilisant des algorithmes d'apprentissage profond, nous pouvons analyser des images médicales, telles que des **IRM** ou des **scanners CT**, avec une précision et une efficacité sans précédent. De plus, il peut aider à la classification des tumeurs cérébrales en différents sous-types. En entraînant des modèles sur de grands ensembles de données d'images de tumeurs cérébrales étiquetées, les algorithmes d'apprentissage profond peuvent apprendre à distinguer les différents types de tumeurs, tels que les gliomes, les méningiomes ou les tumeurs métastatiques. Cette capacité de classification peut aider à déterminer l'approche thérapeutique et le pronostic appropriés pour les patients.\n",
    "\n",
    "Dans l'ensemble, l'apprentissage profond a le potentiel de révolutionner la détection et le diagnostic des tumeurs cérébrales. En exploitant la puissance des réseaux de neurones, nous pouvons améliorer la précision, l'efficacité et la compréhension des images des tumeurs cérébrales, ce qui conduira finalement à de meilleurs soins et résultats pour les patients dans le domaine de la neuro-oncologie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012356,
     "end_time": "2022-12-25T14:49:51.746207",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.733851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>1.2 |</span></b> Énoncé du problème</b></p>\n",
    "</div>\n",
    "\n",
    "La détection et la classification précises des **tumeurs cérébrales** jouent un rôle crucial dans le diagnostic et la planification du traitement des patients. Cependant, l'interprétation manuelle des **images médicales**, telles que les IRM, peut être longue et subjective, ce qui peut entraîner des erreurs et des retards dans les soins aux patients. Par conséquent, il existe un besoin d'une méthode automatisée et fiable pour détecter et classifier les tumeurs cérébrales à partir des images médicales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012443,
     "end_time": "2022-12-25T14:49:51.771818",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.759375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>1.3 |</span></b> Objectif de l'étude</b></p>\n",
    "</div>\n",
    "\n",
    "Cette étude vise à développer un Réseau de Neurones Convolutif **(CNN)** en utilisant le cadre **PyTorch** capable de détecter et de classifier avec précision les **tumeurs cérébrales** à partir des IRM. Le CNN sera entraîné sur un grand ensemble de données d'images de tumeurs cérébrales étiquetées pour apprendre les motifs et les caractéristiques associés aux différents types de tumeurs. L'objectif de l'étude est d'atteindre une haute précision dans la détection et la classification des tumeurs, offrant ainsi un outil précieux pour les professionnels de la santé dans le domaine de la neuro-oncologie. Le but ultime est d'améliorer l'efficacité et la précision du diagnostic des tumeurs cérébrales, permettant ainsi une planification de traitement appropriée et en temps voulu pour les patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012458,
     "end_time": "2022-12-25T14:49:51.822418",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.80996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>2 <span style='color:#e61227'>|</span> Dataset</b> \n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>2.1 |</span></b> Load Dataset</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.722258Z",
     "iopub.status.busy": "2024-12-28T17:05:20.721611Z",
     "iopub.status.idle": "2024-12-28T17:05:20.795739Z",
     "shell.execute_reply": "2024-12-28T17:05:20.795029Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.722227Z"
    },
    "papermill": {
     "duration": 0.614551,
     "end_time": "2022-12-25T14:49:52.44957",
     "exception": false,
     "start_time": "2022-12-25T14:49:51.835019",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('/kaggle/input/brian-tumor-dataset/metadata.csv')\n",
    "print(labels_df.head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.796778Z",
     "iopub.status.busy": "2024-12-28T17:05:20.796579Z",
     "iopub.status.idle": "2024-12-28T17:05:20.810931Z",
     "shell.execute_reply": "2024-12-28T17:05:20.810219Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.796761Z"
    },
    "papermill": {
     "duration": 0.023499,
     "end_time": "2022-12-25T14:49:52.486395",
     "exception": false,
     "start_time": "2022-12-25T14:49:52.462896",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.811976Z",
     "iopub.status.busy": "2024-12-28T17:05:20.811726Z",
     "iopub.status.idle": "2024-12-28T17:05:20.81633Z",
     "shell.execute_reply": "2024-12-28T17:05:20.815563Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.811957Z"
    },
    "papermill": {
     "duration": 0.021089,
     "end_time": "2022-12-25T14:49:52.520259",
     "exception": false,
     "start_time": "2022-12-25T14:49:52.49917",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035324,
     "end_time": "2022-12-25T14:50:13.460476",
     "exception": false,
     "start_time": "2022-12-25T14:50:13.425152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>3 <span style='color:#e61227'>|</span> Data Preparation </b> \n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>3.1 |</span></b> Splitting Dataset</b></p>\n",
    "</div>\n",
    "\n",
    "- Nous devons évaluer le modèle sur les ensembles de validation afin de suivre la performance du modèle pendant l'entraînement. Ensuite, utilisons 20 % de l'ensemble de données pour l'**ensemble de validation** et le reste pour l'**ensemble d'entraînement**, afin d'obtenir une répartition **80/20** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:05:20.817832Z",
     "iopub.status.busy": "2024-12-28T17:05:20.817331Z",
     "iopub.status.idle": "2024-12-28T17:06:08.262999Z",
     "shell.execute_reply": "2024-12-28T17:06:08.262184Z",
     "shell.execute_reply.started": "2024-12-28T17:05:20.817809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Chemin du Dataset\n",
    "data_dir = '/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# Diviser l'ensemble de données en ensembles d'entraînement, de validation et de test\n",
    "splitfolders.ratio(data_dir, output='brain', seed=20, ratio=(0.8, 0.2))\n",
    "\n",
    "\n",
    "# Nouveau chemin du dataset \n",
    "data_dir = '/kaggle/working/brain'\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043602,
     "end_time": "2022-12-25T14:50:17.70179",
     "exception": false,
     "start_time": "2022-12-25T14:50:17.658188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>4 <span style='color:#e61227'>|</span> Image Augmentation Definitions</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:08.264461Z",
     "iopub.status.busy": "2024-12-28T17:06:08.264202Z",
     "iopub.status.idle": "2024-12-28T17:06:08.269155Z",
     "shell.execute_reply": "2024-12-28T17:06:08.268321Z",
     "shell.execute_reply.started": "2024-12-28T17:06:08.264438Z"
    },
    "papermill": {
     "duration": 0.052413,
     "end_time": "2022-12-25T14:50:17.797638",
     "exception": false,
     "start_time": "2022-12-25T14:50:17.745225",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# definir transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:08.270291Z",
     "iopub.status.busy": "2024-12-28T17:06:08.270076Z",
     "iopub.status.idle": "2024-12-28T17:06:08.286556Z",
     "shell.execute_reply": "2024-12-28T17:06:08.285805Z",
     "shell.execute_reply.started": "2024-12-28T17:06:08.270273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Définir un objet de jeu de données personnalisé pour l'entraînement et la validation.\n",
    "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"train\"), transform=transform) \n",
    "train_set.transform\n",
    "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath(\"val\"), transform=transform)\n",
    "val_set.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:08.290286Z",
     "iopub.status.busy": "2024-12-28T17:06:08.29005Z",
     "iopub.status.idle": "2024-12-28T17:06:10.101105Z",
     "shell.execute_reply": "2024-12-28T17:06:10.100305Z",
     "shell.execute_reply.started": "2024-12-28T17:06:08.290267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualiser quelques images de l'ensemble d'entraînement\n",
    "CLA_label = {\n",
    "    0 : 'Brain Tumor',\n",
    "    1 : 'Healthy'\n",
    "} \n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "cols, rows = 4, 4\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(CLA_label[label])\n",
    "    plt.axis(\"off\")\n",
    "    img_np = img.numpy().transpose((1, 2, 0))\n",
    "    #Clipper les valeurs des pixels dans la plage [0, 1]\n",
    "    img_valid_range = np.clip(img_np, 0, 1)\n",
    "    plt.imshow(img_valid_range)\n",
    "    plt.suptitle('Brain Images', y=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044772,
     "end_time": "2022-12-25T14:50:18.077217",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.032445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>5 <span style='color:#e61227'>|</span> Creating Dataloaders</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:10.102494Z",
     "iopub.status.busy": "2024-12-28T17:06:10.102188Z",
     "iopub.status.idle": "2024-12-28T17:06:10.107898Z",
     "shell.execute_reply": "2024-12-28T17:06:10.107141Z",
     "shell.execute_reply.started": "2024-12-28T17:06:10.102465Z"
    },
    "papermill": {
     "duration": 0.057816,
     "end_time": "2022-12-25T14:50:18.183736",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.12592",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import and load train, validation\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:10.109248Z",
     "iopub.status.busy": "2024-12-28T17:06:10.108976Z",
     "iopub.status.idle": "2024-12-28T17:06:11.770386Z",
     "shell.execute_reply": "2024-12-28T17:06:11.769266Z",
     "shell.execute_reply.started": "2024-12-28T17:06:10.109223Z"
    },
    "papermill": {
     "duration": 0.301361,
     "end_time": "2022-12-25T14:50:18.530596",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.229235",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# \"imprimer la forme des données d'entraînement et de validation\"\n",
    "for key, value in {'Training data': train_loader, \"Validation data\": val_loader}.items():\n",
    "    for X, y in value:\n",
    "        print(f\"{key}:\")\n",
    "        print(f\"Shape of X : {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04387,
     "end_time": "2022-12-25T14:50:18.619294",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.575424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>6 <span style='color:#e61227'>|</span> Define Brain Tumor Classifier</b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:11.772267Z",
     "iopub.status.busy": "2024-12-28T17:06:11.771924Z",
     "iopub.status.idle": "2024-12-28T17:06:11.780718Z",
     "shell.execute_reply": "2024-12-28T17:06:11.779913Z",
     "shell.execute_reply.started": "2024-12-28T17:06:11.772234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "''''Cette fonction peut être utile pour déterminer la taille de sortie d'une couche convolutionnelle dans un réseau de neurones, étant donné les dimensions de l'entrée et les paramètres de la couche convolutionnelle.'''\n",
    "\n",
    "def findConv2dOutShape(hin,win,conv,pool=2):\n",
    "    # get conv arguments\n",
    "    kernel_size = conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "\n",
    "    hout=np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout/=pool\n",
    "        wout/=pool\n",
    "    return int(hout),int(wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:11.782098Z",
     "iopub.status.busy": "2024-12-28T17:06:11.781831Z",
     "iopub.status.idle": "2024-12-28T17:06:11.791557Z",
     "shell.execute_reply": "2024-12-28T17:06:11.790637Z",
     "shell.execute_reply.started": "2024-12-28T17:06:11.782079Z"
    },
    "papermill": {
     "duration": 0.061676,
     "end_time": "2022-12-25T14:50:18.724104",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.662428",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Définir l'architecture du modèle CNN_TUMOR\n",
    "class CNN_TUMOR(nn.Module):\n",
    "    \n",
    "    # Initialisation du réseau\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(CNN_TUMOR, self).__init__()\n",
    "    \n",
    "        Cin,Hin,Win = params[\"shape_in\"]\n",
    "        init_f = params[\"initial_filters\"] \n",
    "        num_fc1 = params[\"num_fc1\"]  \n",
    "        num_classes = params[\"num_classes\"] \n",
    "        self.dropout_rate = params[\"dropout_rate\"] \n",
    "        \n",
    "        # Les couches de convolution\n",
    "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(Hin,Win,self.conv1)\n",
    "        self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv2)\n",
    "        self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv3)\n",
    "        self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
    "        h,w=findConv2dOutShape(h,w,self.conv4)\n",
    "        \n",
    "        # Calculer la taille aplatie\n",
    "        self.num_flatten=h*w*8*init_f\n",
    "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
    "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
    "\n",
    "    def forward(self,X):\n",
    "        \n",
    "        # Convolution et couches de pooling\n",
    "        X = F.relu(self.conv1(X)); \n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv4(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, self.num_flatten)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.dropout(X, self.dropout_rate)\n",
    "        X = self.fc2(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:11.793011Z",
     "iopub.status.busy": "2024-12-28T17:06:11.792706Z",
     "iopub.status.idle": "2024-12-28T17:06:12.063376Z",
     "shell.execute_reply": "2024-12-28T17:06:12.062517Z",
     "shell.execute_reply.started": "2024-12-28T17:06:11.792985Z"
    },
    "papermill": {
     "duration": 3.280473,
     "end_time": "2022-12-25T14:50:22.047812",
     "exception": false,
     "start_time": "2022-12-25T14:50:18.767339",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params_model={\n",
    "        \"shape_in\": (3,256,256), \n",
    "        \"initial_filters\": 8,    \n",
    "        \"num_fc1\": 100,\n",
    "        \"dropout_rate\": 0.25,\n",
    "        \"num_classes\": 2}\n",
    "\n",
    "# Créer une instance de la classe Network\n",
    "cnn_model = CNN_TUMOR(params_model)\n",
    "\n",
    "# Définir l'approche matérielle de calcul (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.064973Z",
     "iopub.status.busy": "2024-12-28T17:06:12.064604Z",
     "iopub.status.idle": "2024-12-28T17:06:12.072522Z",
     "shell.execute_reply": "2024-12-28T17:06:12.071519Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.064943Z"
    },
    "papermill": {
     "duration": 6.046363,
     "end_time": "2022-12-25T14:50:28.138838",
     "exception": false,
     "start_time": "2022-12-25T14:50:22.092475",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Résumé du modèle pour le modèle CNN\n",
    "summary(cnn_model, input_size=(3, 256, 256),device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043415,
     "end_time": "2022-12-25T14:50:28.227288",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.183873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>7 <span style='color:#e61227'>|</span> Loss Function Definition</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.074057Z",
     "iopub.status.busy": "2024-12-28T17:06:12.073736Z",
     "iopub.status.idle": "2024-12-28T17:06:12.07808Z",
     "shell.execute_reply": "2024-12-28T17:06:12.077289Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.074029Z"
    },
    "papermill": {
     "duration": 0.051641,
     "end_time": "2022-12-25T14:50:28.322844",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.271203",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043081,
     "end_time": "2022-12-25T14:50:28.409411",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.36633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>8 <span style='color:#e61227'>|</span> Optimiser Definition</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.079386Z",
     "iopub.status.busy": "2024-12-28T17:06:12.079141Z",
     "iopub.status.idle": "2024-12-28T17:06:12.083374Z",
     "shell.execute_reply": "2024-12-28T17:06:12.082602Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.079366Z"
    },
    "papermill": {
     "duration": 0.052279,
     "end_time": "2022-12-25T14:50:28.504879",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.4526",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0434,
     "end_time": "2022-12-25T14:50:28.591572",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.548172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>9 <span style='color:#e61227'>|</span> Training Model</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.08467Z",
     "iopub.status.busy": "2024-12-28T17:06:12.084432Z",
     "iopub.status.idle": "2024-12-28T17:06:12.091468Z",
     "shell.execute_reply": "2024-12-28T17:06:12.090601Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.084651Z"
    },
    "papermill": {
     "duration": 0.055553,
     "end_time": "2022-12-25T14:50:28.690141",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.634588",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fonction pour obtenir le taux d'apprentissage\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "# Fonction pour calculer la valeur de la perte par lot de données\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    \n",
    "    loss = loss_func(output, target) # get loss\n",
    "    pred = output.argmax(dim=1, keepdim=True) # Get Output Class\n",
    "    metric_b=pred.eq(target.view_as(pred)).sum().item() # get performance metric\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "# Calculer la valeur de la perte et les métriques de performance pour l'ensemble du dataset (époque)\n",
    "def loss_epoch(model,loss_func,dataset_dl,opt=None):\n",
    "    \n",
    "    run_loss=0.0 \n",
    "    t_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "\n",
    "    # boucle interne sur le dataset\n",
    "    for xb, yb in dataset_dl:\n",
    "        # Déplacer le lot vers le périphérique\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb) # Obtenir la sortie du modèle\n",
    "        loss_b,metric_b=loss_batch(loss_func, output, yb, opt) # Obtenir la perte par lot\n",
    "        run_loss+=loss_b        # Mettre à jour la perte cumulative\n",
    "\n",
    "        if metric_b is not None: # Mettre à jour la métrique en cours\n",
    "            t_metric+=metric_b    \n",
    "    \n",
    "    loss=run_loss/float(len_data)  # Valeur de la perte moyenne\n",
    "    metric=t_metric/float(len_data) # Valeur moyenne de la métrique\n",
    "    \n",
    "    return loss, metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042867,
     "end_time": "2022-12-25T14:50:28.870731",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.827864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>9.2 |</span></b> Training Function</b></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.093289Z",
     "iopub.status.busy": "2024-12-28T17:06:12.092939Z",
     "iopub.status.idle": "2024-12-28T17:06:12.101656Z",
     "shell.execute_reply": "2024-12-28T17:06:12.100829Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.093261Z"
    },
    "papermill": {
     "duration": 0.095856,
     "end_time": "2022-12-25T14:50:29.009269",
     "exception": false,
     "start_time": "2022-12-25T14:50:28.913413",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Train_Val(model, params,verbose=False):\n",
    "    \n",
    "    # Obtenir les paramètres\n",
    "    epochs=params[\"epochs\"]\n",
    "    loss_func=params[\"f_loss\"]\n",
    "    opt=params[\"optimiser\"]\n",
    "    train_dl=params[\"train\"]\n",
    "    val_dl=params[\"val\"]\n",
    "    lr_scheduler=params[\"lr_change\"]\n",
    "    weight_path=params[\"weight_path\"]\n",
    "    \n",
    "    # Historique des valeurs de perte à chaque époque\n",
    "    loss_history={\"train\": [],\"val\": []} \n",
    "    # Historique des valeurs des métriques à chaque époque\n",
    "    metric_history={\"train\": [],\"val\": []} \n",
    "    # Une copie profonde des poids pour le meilleur modèle performant\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "    # Initialiser la meilleure perte à une valeur élevée\n",
    "    best_loss=float('inf') \n",
    "\n",
    "# Entraîner le modèle pendant n_epochs (la progression de l'entraînement en imprimant le numéro de l'époque et le taux d'apprentissage associé.) \n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # Obtenir le taux d'apprentissage\n",
    "        current_lr=get_lr(opt)\n",
    "        if(verbose):\n",
    "            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\n",
    "\n",
    "        \n",
    "# Le processus d'entraînement du modèle\n",
    "\n",
    "        \n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,opt)\n",
    "\n",
    "        # collecter les pertes\n",
    "        loss_history[\"train\"].append(train_loss)\n",
    "        metric_history[\"train\"].append(train_metric)\n",
    "        \n",
    "\n",
    "# Évaluer le processus du modèle\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model,loss_func,val_dl)\n",
    "        \n",
    "        # Stocker le meilleur modèle\n",
    "        if(val_loss < best_loss):\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Stocker les poids dans un fichier local\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "            if(verbose):\n",
    "                print(\"Copied best model weights!\")\n",
    "        \n",
    "        # Collecter la perte et la métrique pour le jeu de données de validation\n",
    "        loss_history[\"val\"].append(val_loss)\n",
    "        metric_history[\"val\"].append(val_metric)\n",
    "        \n",
    "        # Planification du taux d'apprentissage\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            if(verbose):\n",
    "                print(\"Loading best model weights!\")\n",
    "            model.load_state_dict(best_model_wts) \n",
    "\n",
    "        if(verbose):\n",
    "            print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
    "            print(\"-\"*10) \n",
    "\n",
    "    # Charger les poids du meilleur modèle\n",
    "    model.load_state_dict(best_model_wts)\n",
    "        \n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04377,
     "end_time": "2022-12-25T14:50:29.097122",
     "exception": false,
     "start_time": "2022-12-25T14:50:29.053352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>9.3 |</span></b> Training Process </b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:06:12.10295Z",
     "iopub.status.busy": "2024-12-28T17:06:12.102688Z",
     "iopub.status.idle": "2024-12-28T17:18:33.294306Z",
     "shell.execute_reply": "2024-12-28T17:18:33.293139Z",
     "shell.execute_reply.started": "2024-12-28T17:06:12.10293Z"
    },
    "papermill": {
     "duration": 339.54529,
     "end_time": "2022-12-25T14:56:08.685628",
     "exception": false,
     "start_time": "2022-12-25T14:50:29.140338",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Définir divers paramètres utilisés pour l'entraînement et l'évaluation d'un modèle CNN\n",
    "\n",
    "params_train={\n",
    " \"train\": train_loader,\"val\": val_loader,\n",
    " \"epochs\": 60,\n",
    " \"optimiser\": optim.Adam(cnn_model.parameters(),lr=3e-4),\n",
    " \"lr_change\": ReduceLROnPlateau(opt,\n",
    "                                mode='min',\n",
    "                                factor=0.5,\n",
    "                                patience=20,\n",
    "                                verbose=0),\n",
    " \"f_loss\": nn.NLLLoss(reduction=\"sum\"),\n",
    " \"weight_path\": \"weights.pt\",\n",
    "}\n",
    "\n",
    "# Entraîner et valider le modèle \n",
    "cnn_model,loss_hist,metric_hist = Train_Val(cnn_model,params_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045473,
     "end_time": "2022-12-25T14:56:10.029988",
     "exception": false,
     "start_time": "2022-12-25T14:56:09.984515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <b>10 <span style='color:#e61227'>|</span> Evaluation Metric Visualization </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:18:33.295965Z",
     "iopub.status.busy": "2024-12-28T17:18:33.295661Z",
     "iopub.status.idle": "2024-12-28T17:18:33.952864Z",
     "shell.execute_reply": "2024-12-28T17:18:33.952087Z",
     "shell.execute_reply.started": "2024-12-28T17:18:33.295941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tracé de l'historique de convergence\n",
    "epochs=params_train[\"epochs\"]\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\n",
    "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#03112A;font-size:150%;\n",
    "            letter-spacing:1.0px;background-image: url(https://i.imgur.com/GVd0La1.png)\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b><b><span style='color:#e61227'>10.2 |</span></b> Confusion_Matrix </b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:18:33.954366Z",
     "iopub.status.busy": "2024-12-28T17:18:33.954018Z",
     "iopub.status.idle": "2024-12-28T17:18:36.481721Z",
     "shell.execute_reply": "2024-12-28T17:18:36.480738Z",
     "shell.execute_reply.started": "2024-12-28T17:18:33.954334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Définir une fonction pour le rapport de classification\n",
    "def Ture_and_Pred(val_loader, model):\n",
    "    i = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.numpy()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        \n",
    "        y_true = np.append(y_true, labels)\n",
    "        y_pred = np.append(y_pred, pred)\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "# Vérifier la matrice de confusion pour l'analyse des erreurs\n",
    "y_true, y_pred = Ture_and_Pred(val_loader, cnn_model)\n",
    "\n",
    "print(classification_report(y_true, y_pred), '\\n\\n')\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:18:36.48409Z",
     "iopub.status.busy": "2024-12-28T17:18:36.483381Z",
     "iopub.status.idle": "2024-12-28T17:18:36.806069Z",
     "shell.execute_reply": "2024-12-28T17:18:36.805204Z",
     "shell.execute_reply.started": "2024-12-28T17:18:36.484055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Fonction de tracé de la matrice de confusion\n",
    "def show_confusion_matrix(cm, CLA_label, title='Confusion matrix', cmap=plt.cm.YlGnBu):\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(CLA_label))\n",
    "\n",
    "    plt.xticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()], rotation=45)\n",
    "    plt.yticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()])\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i,j]}\\n{cm[i,j]/np.sum(cm)*100:.2f}%\", horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_confusion_matrix(cm, CLA_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>11<span style='color:#e61227'>|</span> Save Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:18:36.807338Z",
     "iopub.status.busy": "2024-12-28T17:18:36.807093Z",
     "iopub.status.idle": "2024-12-28T17:18:36.819515Z",
     "shell.execute_reply": "2024-12-28T17:18:36.818565Z",
     "shell.execute_reply.started": "2024-12-28T17:18:36.807318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(cnn_model, \"Brain_Tumor_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1343913,
     "sourceId": 2236708,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
